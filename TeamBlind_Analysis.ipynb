{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf4fe0d-10c9-4475-99eb-4560529dfe3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\thety\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: gensim in c:\\users\\thety\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: pyLDAvis in c:\\users\\thety\\anaconda3\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from gensim) (1.11.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from gensim) (2.0.9)\n",
      "Requirement already satisfied: pandas>=2.0.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.2.0)\n",
      "Requirement already satisfied: numexpr in c:\\users\\thety\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.8.7)\n",
      "Requirement already satisfied: funcy in c:\\users\\thety\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.6.1)\n",
      "Requirement already satisfied: pyfume in c:\\users\\thety\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (0.3.1)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.5.0)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\thety\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: simpful in c:\\users\\thety\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.12.0)\n",
      "Requirement already satisfied: fst-pso in c:\\users\\thety\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: miniful in c:\\users\\thety\\anaconda3\\lib\\site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 393.8 kB/s eta 0:00:33\n",
      "     --------------------------------------- 0.1/12.8 MB 435.7 kB/s eta 0:00:30\n",
      "     --------------------------------------- 0.1/12.8 MB 708.1 kB/s eta 0:00:18\n",
      "      --------------------------------------- 0.2/12.8 MB 1.0 MB/s eta 0:00:13\n",
      "     - -------------------------------------- 0.4/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.6/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 0.9/12.8 MB 2.4 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 1.2/12.8 MB 3.0 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 3.3 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 1.9/12.8 MB 3.7 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 2.0/12.8 MB 3.9 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 2.0/12.8 MB 3.9 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 2.2/12.8 MB 3.3 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 2.2/12.8 MB 3.4 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 2.3/12.8 MB 3.1 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 2.5/12.8 MB 3.1 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 2.6/12.8 MB 3.1 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 2.9/12.8 MB 3.3 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 3.2/12.8 MB 3.4 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 3.5 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 3.9/12.8 MB 3.8 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.3/12.8 MB 4.0 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.6/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.6/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.6/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.6/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.6/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.6/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.3/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.7/12.8 MB 4.7 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 4.8 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.8/12.8 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.2/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.6/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.9/12.8 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 5.2 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.6/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.6/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.6/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.3/12.8 MB 5.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 5.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 7.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 6.9 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Requirement already satisfied: transformers in c:\\users\\thety\\anaconda3\\lib\\site-packages (4.51.2)\n",
      "Requirement already satisfied: torch in c:\\users\\thety\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\thety\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\thety\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\thety\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\thety\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\thety\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thety\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy gensim pyLDAvis\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b007867-40d1-49fe-ab56-671f5b9f72bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing_extensions in c:\\users\\thety\\anaconda3\\lib\\site-packages (4.13.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9def0973-0fa4-44e7-b275-e4b4b528a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all tools needed\n",
    "import pandas as pd #work w/tables\n",
    "import re #clean text \n",
    "import nltk #natural language processing \n",
    "import spacy #nlp to process text\n",
    "import gensim #topic modeling library (LDA)\n",
    "import pyLDAvis #visalize topic models\n",
    "import pyLDAvis.gensim_models #^\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax #model scores to readable probabilities\n",
    "from gensim import corpora #create word-to-id dict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #handle stop words\n",
    "from nltk.corpus import stopwords #common word list\n",
    "from nltk.stem import WordNetLemmatizer #reduce words to base\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "100aee3d-641b-4805-b43b-fa3d67d84a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thety\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\thety\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')  #download the list of common stopwords\n",
    "nltk.download('wordnet')  #download the tool that helps us simplify words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25bba75-1084-44ba-85eb-e2999ad22c70",
   "metadata": {},
   "source": [
    "## Three of the most popular posts (most commented) regarding reasons for quitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b066ca8e-9bfb-4dbd-8e0a-2339330eb268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Company</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nov 12, 2019</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Bad manager. Bad manager. Bad manager.\\n\\nWith...</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nov 12, 2019</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>You don't quit the company, you quit your mana...</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nov 12, 2019</td>\n",
       "      <td>Google</td>\n",
       "      <td>For 61% increase in compensation and 21% incre...</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nov 12, 2019</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>I was getting extremely stressed out, and soug...</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nov 12, 2019</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Bad manager - didn't believe one manager could...</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Company                                            Comment  \\\n",
       "0  Nov 12, 2019     Amazon  Bad manager. Bad manager. Bad manager.\\n\\nWith...   \n",
       "1  Nov 12, 2019   Facebook  You don't quit the company, you quit your mana...   \n",
       "2  Nov 12, 2019     Google  For 61% increase in compensation and 21% incre...   \n",
       "3  Nov 12, 2019     Airbnb  I was getting extremely stressed out, and soug...   \n",
       "4  Nov 12, 2019  Microsoft  Bad manager - didn't believe one manager could...   \n",
       "\n",
       "   Likes  \n",
       "0   67.0  \n",
       "1   41.0  \n",
       "2   37.0  \n",
       "3   33.0  \n",
       "4   35.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blind comments from post 1\n",
    "# https://www.teamblind.com/post/Why-did-you-quit-your-last-job-8WJinT7p\n",
    "\n",
    "df = pd.read_csv(\"Blind_Comments_Post_1.csv\")\n",
    "# Dropping URL column automatically created\n",
    "df.drop(columns=['web-scraper-order', 'web-scraper-start-url'], inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76b814af-3e85-4740-9298-548452c6b390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Company</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>May 13, 2018</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Lowest caliber of people and ceiling of ambiti...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>May 13, 2018</td>\n",
       "      <td>Oath</td>\n",
       "      <td>I didn’t think I need a reason to quit Oath</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>May 13, 2018</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>I quit Google shortly after I got my green car...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>May 13, 2018</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Quit previous role because of the enticement o...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May 13, 2018</td>\n",
       "      <td>Snapchat</td>\n",
       "      <td>Burn out</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date   Company                                            Comment  \\\n",
       "0  May 13, 2018    Amazon  Lowest caliber of people and ceiling of ambiti...   \n",
       "1  May 13, 2018      Oath        I didn’t think I need a reason to quit Oath   \n",
       "2  May 13, 2018  Facebook  I quit Google shortly after I got my green car...   \n",
       "3  May 13, 2018  Facebook  Quit previous role because of the enticement o...   \n",
       "4  May 13, 2018  Snapchat                                           Burn out   \n",
       "\n",
       "   Likes  \n",
       "0    8.0  \n",
       "1   13.0  \n",
       "2    9.0  \n",
       "3    6.0  \n",
       "4    5.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blind comments from post 2\n",
    "# https://www.teamblind.com/post/Why-did-you-quit-your-last-job-oxLGsaPt\n",
    "\n",
    "df2 = pd.read_csv(\"Blind_Comments_Post_2.csv\")\n",
    "# Dropping URL column automatically created\n",
    "df2.drop(columns=['web-scraper-order', 'web-scraper-start-url'], inplace = True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7afcaf16-5f63-4108-b499-faa243c691c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Company</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feb 19, 2020</td>\n",
       "      <td>Target</td>\n",
       "      <td>Manager said my work didnt warrant a promotion...</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feb 19, 2020</td>\n",
       "      <td>Ultimate Software</td>\n",
       "      <td>Can we add \"bad manager\" to the list?\\n\\nMy TC...</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feb 19, 2020</td>\n",
       "      <td>Zymergen</td>\n",
       "      <td>I quit my last company and joined Zymergen bec...</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feb 19, 2020</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>I grew up in a poor family; where I couldn't f...</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feb 19, 2020</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>I know a lot of people are not switching becau...</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date            Company  \\\n",
       "0  Feb 19, 2020             Target   \n",
       "1  Feb 19, 2020  Ultimate Software   \n",
       "2  Feb 19, 2020           Zymergen   \n",
       "3  Feb 19, 2020             Amazon   \n",
       "4  Feb 19, 2020           LinkedIn   \n",
       "\n",
       "                                             Comment  Likes  \n",
       "0  Manager said my work didnt warrant a promotion...  115.0  \n",
       "1  Can we add \"bad manager\" to the list?\\n\\nMy TC...   76.0  \n",
       "2  I quit my last company and joined Zymergen bec...   24.0  \n",
       "3  I grew up in a poor family; where I couldn't f...   25.0  \n",
       "4  I know a lot of people are not switching becau...   31.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blind comments from post 3\n",
    "# https://www.teamblind.com/post/why-do-you-quit-ee80oepK\n",
    "\n",
    "df3 = pd.read_csv(\"Blind_Comments_Post_3.csv\")\n",
    "# Dropping URL column automatically created\n",
    "df3.drop(columns=['web-scraper-order', 'web-scraper-start-url'], inplace = True)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6a9fd1-7362-487a-98f7-8acc3274d296",
   "metadata": {},
   "source": [
    "### Combining data from comment threads above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "337df3d1-a82e-45fc-9481-d6bb6f415c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Company</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nov 12, 2019</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Bad manager. Bad manager. Bad manager.\\n\\nWith...</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nov 12, 2019</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>You don't quit the company, you quit your mana...</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nov 12, 2019</td>\n",
       "      <td>Google</td>\n",
       "      <td>For 61% increase in compensation and 21% incre...</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nov 12, 2019</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>I was getting extremely stressed out, and soug...</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nov 12, 2019</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Bad manager - didn't believe one manager could...</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Feb 19, 2020</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Mo’ TC!</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Feb 19, 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TC is lagging due to management thinking they ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Feb 19, 2020</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>A clean start?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>Feb 19, 2020</td>\n",
       "      <td>Credit Karma</td>\n",
       "      <td>Boredom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Feb 19, 2020</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>If you make this multiple choice ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date       Company  \\\n",
       "0    Nov 12, 2019        Amazon   \n",
       "1    Nov 12, 2019      Facebook   \n",
       "2    Nov 12, 2019        Google   \n",
       "3    Nov 12, 2019        Airbnb   \n",
       "4    Nov 12, 2019     Microsoft   \n",
       "..            ...           ...   \n",
       "423  Feb 19, 2020      Deloitte   \n",
       "424  Feb 19, 2020           NaN   \n",
       "425  Feb 19, 2020          Lyft   \n",
       "426  Feb 19, 2020  Credit Karma   \n",
       "427  Feb 19, 2020          Lyft   \n",
       "\n",
       "                                               Comment  Likes  \n",
       "0    Bad manager. Bad manager. Bad manager.\\n\\nWith...   67.0  \n",
       "1    You don't quit the company, you quit your mana...   41.0  \n",
       "2    For 61% increase in compensation and 21% incre...   37.0  \n",
       "3    I was getting extremely stressed out, and soug...   33.0  \n",
       "4    Bad manager - didn't believe one manager could...   35.0  \n",
       "..                                                 ...    ...  \n",
       "423                                            Mo’ TC!    NaN  \n",
       "424  TC is lagging due to management thinking they ...    NaN  \n",
       "425                                     A clean start?    NaN  \n",
       "426                                            Boredom    NaN  \n",
       "427               If you make this multiple choice ...    NaN  \n",
       "\n",
       "[428 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_blind_quit_comments = pd.concat([df, df2, df3], ignore_index=True)\n",
    "full_blind_quit_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1b0b431-2429-4be7-b90b-427551cc5f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_blind_quit_comments.to_csv('full_negative_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d6af3da-8888-4660-b110-95ceb4e5ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "full_blind_quit_comments['Likes'] = full_blind_quit_comments['Likes'].fillna(0)  # replace NaN likes with 0\n",
    "\n",
    "#lowercase, remove punctuation/numbers\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)            #keep letters and spaces\n",
    "    return text\n",
    "\n",
    "def tokenize_no_stopword_removal(text):\n",
    "    words = text.split()\n",
    "    #keep stopwords for bigrams\n",
    "    return ' '.join([word for word in words if len(word) > 2])\n",
    "\n",
    "#apply both steps\n",
    "full_blind_quit_comments['cleaned_text'] = full_blind_quit_comments['Comment'].apply(clean_text)\n",
    "full_blind_quit_comments['processed_text'] = full_blind_quit_comments['cleaned_text'].apply(tokenize_no_stopword_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a9775-6ce5-4d0c-9e98-3d1d832a5bfb",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis - Using steps from Adriana's Reddit Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaf04199-fd77-4ad3-ac9d-f0d35e64f2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 30 TF-IDF Terms:\n",
      "\n",
      "                term  average_tfidf\n",
      "         bad manager       0.027875\n",
      "      bad management       0.010535\n",
      "            bad boss       0.007725\n",
      "         increase tc       0.006854\n",
      "         tc increase       0.006765\n",
      "           got fired       0.006201\n",
      "        shit manager       0.004992\n",
      "         manager bad       0.004623\n",
      "           make poll       0.004474\n",
      "              low tc       0.004194\n",
      "        pay increase       0.003913\n",
      "           got bored       0.003829\n",
      "growth opportunities       0.003609\n",
      "    previous company       0.003599\n",
      "         current job       0.003470\n",
      "        job security       0.003327\n",
      "       quit previous       0.003277\n",
      "     poor leadership       0.003196\n",
      "           tc growth       0.003178\n",
      "        bad managers       0.003007\n",
      "      shitty manager       0.002937\n",
      "         wanted work       0.002922\n",
      "     poor management       0.002887\n",
      "      direct manager       0.002878\n",
      "      leave managers       0.002877\n",
      "  growth opportunity       0.002647\n",
      "       number reason       0.002582\n",
      "             new job       0.002573\n",
      "       leave current       0.002426\n",
      "       toxic culture       0.002422\n"
     ]
    }
   ],
   "source": [
    "#set up TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=\"english\",     #remove common boring words\n",
    "    ngram_range=(2,2),       #include bigrams\n",
    ")\n",
    "\n",
    "#fit TF-IDF to cleaned Blind comments\n",
    "tfidf_matrix = vectorizer.fit_transform(full_blind_quit_comments['cleaned_text'])\n",
    "\n",
    "#convert to df\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "#get top 30 average TF-IDF terms\n",
    "top_scores = tfidf_df.mean().sort_values(ascending=False).head(30).reset_index()\n",
    "top_scores.columns = ['term', 'average_tfidf']\n",
    "\n",
    "print(\"\\nTop 30 TF-IDF Terms:\\n\")\n",
    "print(top_scores.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f66edc82-7c9d-4c3f-8ee4-cb89166faf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Topic 1: 0.061*\"culture\" + 0.059*\"leadership\" + 0.053*\"people\" + 0.052*\"care\" + 0.048*\"toxic\" + 0.047*\"company\" + 0.044*\"know\" + 0.042*\"good\" + 0.037*\"team\" + 0.036*\"promotion\"\n",
      "\n",
      " Topic 2: 0.182*\"growth\" + 0.120*\"opportunity\" + 0.110*\"low\" + 0.060*\"lack\" + 0.057*\"compensation\" + 0.048*\"manager\" + 0.046*\"good\" + 0.043*\"go\" + 0.033*\"career\" + 0.029*\"culture\"\n",
      "\n",
      " Topic 3: 0.098*\"work\" + 0.089*\"company\" + 0.051*\"get\" + 0.049*\"manager\" + 0.046*\"quit\" + 0.036*\"new\" + 0.035*\"time\" + 0.034*\"job\" + 0.033*\"year\" + 0.027*\"increase\"\n",
      "\n",
      " Topic 4: 0.113*\"management\" + 0.077*\"bad\" + 0.075*\"boss\" + 0.067*\"work\" + 0.062*\"want\" + 0.042*\"big\" + 0.041*\"well\" + 0.040*\"product\" + 0.037*\"toxic\" + 0.035*\"wlb\"\n",
      "\n",
      " Topic 5: 0.221*\"job\" + 0.069*\"money\" + 0.058*\"leave\" + 0.051*\"current\" + 0.046*\"salary\" + 0.042*\"role\" + 0.035*\"high\" + 0.034*\"new\" + 0.030*\"pay\" + 0.029*\"culture\"\n",
      "\n",
      " Topic 6: 0.357*\"manager\" + 0.186*\"bad\" + 0.075*\"leave\" + 0.038*\"company\" + 0.037*\"team\" + 0.034*\"people\" + 0.023*\"shit\" + 0.022*\"change\" + 0.022*\"know\" + 0.018*\"management\"\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def clean_for_lda(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc \n",
    "            if token.pos_ in [\"NOUN\", \"ADJ\", \"VERB\"]\n",
    "            and not token.is_stop\n",
    "            and len(token) > 2]\n",
    "\n",
    "#apply to cleaned txt\n",
    "full_blind_quit_comments[\"lda_tokens\"] = full_blind_quit_comments[\"cleaned_text\"].apply(clean_for_lda)\n",
    "full_blind_quit_comments[\"lda_tokens\"].head()\n",
    "\n",
    "#create dict that assigns an ID to every unique word (used by LDA)\n",
    "dictionary = corpora.Dictionary(full_blind_quit_comments[\"lda_tokens\"])\n",
    "\n",
    "#filter out rare words (appear in <10 docs) and too common words (>50% of docs)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.50)\n",
    "\n",
    "#converts each doc into bag-of-words format (list of (word_id, count) pairs)\n",
    "#input format LDA needs\n",
    "corpus = [dictionary.doc2bow(text) for text in full_blind_quit_comments[\"lda_tokens\"]]\n",
    "\n",
    "#train LDA model\n",
    "lda_model = gensim.models.LdaModel(\n",
    "    corpus=corpus,             #bag-of-words data\n",
    "    id2word=dictionary,        #word-to-ID mapping\n",
    "    num_topics=6,              #how many topics to find\n",
    "    random_state=15,           #for reproducibility \n",
    "    passes=10,                 #number of training passes (more = better, slower)\n",
    "    alpha='auto'               #automatically tune topic distribution sparsity\n",
    ")\n",
    "\n",
    "#view discovered topics \n",
    "for i, topic in lda_model.show_topics(num_words=10, formatted=True):\n",
    "    print(f\"\\n Topic {i+1}: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e721b83a-3e35-4ff6-b97c-00122c144f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyLDAvis.enable_notebook()\n",
    "\n",
    "# vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
    "# pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c7158322-a893-4756-a994-61f69b6b9db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\thety\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63061a5f-ed0e-4390-809e-3bcc136bdfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don't know where to start:\\n- Worst CTO\\n- 0 T...</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad boss. He was demeaning and would yell at m...</td>\n",
       "      <td>-0.949</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Culture changing, wanting to learn new things ...</td>\n",
       "      <td>-0.934</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Bad manager (VP of Product)\\n- mediocre Java...</td>\n",
       "      <td>-0.926</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’m heavily considering leaving.\\n\\nMy manager...</td>\n",
       "      <td>-0.922</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Because things were an absolute mess, the proj...</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bad manager. Bad manager. Bad manager.\\n\\nWith...</td>\n",
       "      <td>-0.898</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Imagine working for a CEO and board who openly...</td>\n",
       "      <td>-0.898</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Microsoft got rid of my team. I got an officia...</td>\n",
       "      <td>-0.896</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Left Oracle because:\\n- terrible manager\\n- no...</td>\n",
       "      <td>-0.896</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>My last job, I hated the coworkers and company...</td>\n",
       "      <td>-0.893</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I left because I had a horrible manager who go...</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1. Bad manager\\n2. Bad manager\\n3. Bad manager...</td>\n",
       "      <td>-0.888</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bad manager, bad company, bad project that I g...</td>\n",
       "      <td>-0.888</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1- bad manager\\n2 - bad manager\\n3- bad manager</td>\n",
       "      <td>-0.888</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>And here I am planning to leave cause, I am on...</td>\n",
       "      <td>-0.887</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Shitty manager. Highly insecure and was being ...</td>\n",
       "      <td>-0.886</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Shitty policies, incompetent management swirle...</td>\n",
       "      <td>-0.869</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>My Indian manager who discriminated me for bei...</td>\n",
       "      <td>-0.863</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>No room for advancement and my manager was a p...</td>\n",
       "      <td>-0.840</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment  sentiment_score  \\\n",
       "0   Don't know where to start:\\n- Worst CTO\\n- 0 T...           -0.958   \n",
       "1   Bad boss. He was demeaning and would yell at m...           -0.949   \n",
       "2   Culture changing, wanting to learn new things ...           -0.934   \n",
       "3   - Bad manager (VP of Product)\\n- mediocre Java...           -0.926   \n",
       "4   I’m heavily considering leaving.\\n\\nMy manager...           -0.922   \n",
       "5   Because things were an absolute mess, the proj...           -0.910   \n",
       "6   Bad manager. Bad manager. Bad manager.\\n\\nWith...           -0.898   \n",
       "7   Imagine working for a CEO and board who openly...           -0.898   \n",
       "8   Microsoft got rid of my team. I got an officia...           -0.896   \n",
       "9   Left Oracle because:\\n- terrible manager\\n- no...           -0.896   \n",
       "10  My last job, I hated the coworkers and company...           -0.893   \n",
       "11  I left because I had a horrible manager who go...           -0.891   \n",
       "12  1. Bad manager\\n2. Bad manager\\n3. Bad manager...           -0.888   \n",
       "13  Bad manager, bad company, bad project that I g...           -0.888   \n",
       "14    1- bad manager\\n2 - bad manager\\n3- bad manager           -0.888   \n",
       "15  And here I am planning to leave cause, I am on...           -0.887   \n",
       "16  Shitty manager. Highly insecure and was being ...           -0.886   \n",
       "17  Shitty policies, incompetent management swirle...           -0.869   \n",
       "18  My Indian manager who discriminated me for bei...           -0.863   \n",
       "19  No room for advancement and my manager was a p...           -0.840   \n",
       "\n",
       "   vader_sentiment  \n",
       "0         Negative  \n",
       "1         Negative  \n",
       "2         Negative  \n",
       "3         Negative  \n",
       "4         Negative  \n",
       "5         Negative  \n",
       "6         Negative  \n",
       "7         Negative  \n",
       "8         Negative  \n",
       "9         Negative  \n",
       "10        Negative  \n",
       "11        Negative  \n",
       "12        Negative  \n",
       "13        Negative  \n",
       "14        Negative  \n",
       "15        Negative  \n",
       "16        Negative  \n",
       "17        Negative  \n",
       "18        Negative  \n",
       "19        Negative  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#apply VADER sentiment to each cleaned comment \n",
    "full_blind_quit_comments[\"sentiment_score\"] = full_blind_quit_comments[\"cleaned_text\"].apply(lambda text: vader.polarity_scores(text)[\"compound\"])\n",
    "\n",
    "#preview df\n",
    "sentiment_preview = full_blind_quit_comments[[\"Comment\", \"sentiment_score\"]].copy()\n",
    "\n",
    "#round for neatness\n",
    "sentiment_preview[\"sentiment_score\"] = sentiment_preview[\"sentiment_score\"].round(3)\n",
    "\n",
    "#sort by most negative sentiment\n",
    "sentiment_preview = sentiment_preview.sort_values(by=\"sentiment_score\").reset_index(drop=True)\n",
    "\n",
    "def label_sentiment(score):\n",
    "    if score >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "full_blind_quit_comments[\"vader_sentiment\"] = full_blind_quit_comments[\"sentiment_score\"].apply(label_sentiment)\n",
    "\n",
    "#display table w/sentiment score & whether it's pos, neut, or neg.\n",
    "sentiment_table = full_blind_quit_comments[[\"Comment\", \"sentiment_score\", \"vader_sentiment\"]].copy()\n",
    "sentiment_table[\"sentiment_score\"] = sentiment_table[\"sentiment_score\"].round(3)\n",
    "sentiment_table = sentiment_table.sort_values(by=\"sentiment_score\").reset_index(drop=True)\n",
    "display(sentiment_table.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c599d9a2-3c45-4b3c-80d4-1e2edc40f812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>205</td>\n",
       "      <td>47.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>80</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>143</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment  Count  Percent\n",
       "0  Negative    205     47.9\n",
       "2   Neutral     80     18.7\n",
       "1  Positive    143     33.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#count the # of comments in each sentiment category\n",
    "sentiment_counts = full_blind_quit_comments[\"vader_sentiment\"].value_counts().reset_index()\n",
    "sentiment_counts.columns = [\"Sentiment\", \"Count\"]\n",
    "\n",
    "#calculate percentage\n",
    "total_comments = sentiment_counts[\"Count\"].sum()\n",
    "sentiment_counts[\"Percent\"] = (sentiment_counts[\"Count\"] / total_comments * 100).round(1)\n",
    "\n",
    "#display\n",
    "sentiment_counts = sentiment_counts.sort_values(by=\"Sentiment\")  # Optional alphabetical sort\n",
    "display(sentiment_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7269d6-b7b5-4365-9528-a133a12f9444",
   "metadata": {},
   "source": [
    "### Exact same issue as Adriana with the Reddit Comments (just wanted to double check) - Seems BERT is the optimal route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "17edcb30-de5f-413c-a694-8f3c55c5784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run BERT Sentiment on comments\n",
    "#load the model & tokenizer\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "#function to get sentiment label\n",
    "def get_bert_sentiment(text):\n",
    "    #512 tokens max or it breaks\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    probs = softmax(logits.numpy()[0])\n",
    "    \n",
    "    label_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "    return label_map[probs.argmax()]\n",
    "\n",
    "\n",
    "#apply to df\n",
    "full_blind_quit_comments[\"bert_sentiment\"] = full_blind_quit_comments[\"Comment\"].apply(get_bert_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a56d6c17-95e9-45bb-a734-19d6d130019d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>bert_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad manager. Bad manager. Bad manager.\\n\\nWith...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You don't quit the company, you quit your mana...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For 61% increase in compensation and 21% incre...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was getting extremely stressed out, and soug...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad manager - didn't believe one manager could...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1. Bad manager\\n2. Bad manager\\n3. Bad manager...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Who blocks stack overflow?</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In Soviet Russia, job quits you.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Toxicity and back stabbing.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bro culture and a douche of a CEO. Sued his as...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment bert_sentiment\n",
       "0  Bad manager. Bad manager. Bad manager.\\n\\nWith...       Negative\n",
       "1  You don't quit the company, you quit your mana...       Negative\n",
       "2  For 61% increase in compensation and 21% incre...        Neutral\n",
       "3  I was getting extremely stressed out, and soug...        Neutral\n",
       "4  Bad manager - didn't believe one manager could...       Negative\n",
       "5  1. Bad manager\\n2. Bad manager\\n3. Bad manager...       Negative\n",
       "6                         Who blocks stack overflow?        Neutral\n",
       "7                   In Soviet Russia, job quits you.       Negative\n",
       "8                        Toxicity and back stabbing.       Negative\n",
       "9  Bro culture and a douche of a CEO. Sued his as...       Negative"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results\n",
    "\n",
    "full_blind_quit_comments[[\"Comment\", \"bert_sentiment\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "72b7a190-b0e8-4b53-aa44-6ff0e33f7211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>256</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>127</td>\n",
       "      <td>29.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>45</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment  Count  Percent\n",
       "0  Negative    256     59.8\n",
       "1   Neutral    127     29.7\n",
       "2  Positive     45     10.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_counts = full_blind_quit_comments[\"bert_sentiment\"].value_counts().reset_index()\n",
    "bert_counts.columns = [\"Sentiment\", \"Count\"]\n",
    "bert_counts[\"Percent\"] = (bert_counts[\"Count\"] / bert_counts[\"Count\"].sum() * 100).round(1)\n",
    "\n",
    "display(bert_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c2e6cc36-095d-467c-9d95-8fec3bc4f2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>VADER Count</th>\n",
       "      <th>BERT Count</th>\n",
       "      <th>VADER %</th>\n",
       "      <th>BERT %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>205</td>\n",
       "      <td>256</td>\n",
       "      <td>47.9</td>\n",
       "      <td>59.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>80</td>\n",
       "      <td>127</td>\n",
       "      <td>18.7</td>\n",
       "      <td>29.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>143</td>\n",
       "      <td>45</td>\n",
       "      <td>33.4</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment  VADER Count  BERT Count  VADER %  BERT %\n",
       "0  Negative          205         256     47.9    59.8\n",
       "1   Neutral           80         127     18.7    29.7\n",
       "2  Positive          143          45     33.4    10.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get counts\n",
    "vader_counts = full_blind_quit_comments[\"vader_sentiment\"].value_counts().sort_index()\n",
    "bert_counts = full_blind_quit_comments[\"bert_sentiment\"].value_counts().sort_index()\n",
    "\n",
    "#get total for each model\n",
    "total_vader = vader_counts.sum()\n",
    "total_bert = bert_counts.sum()\n",
    "\n",
    "#combine into one df\n",
    "sentiment_totals = pd.DataFrame({\n",
    "    \"VADER Count\": vader_counts,\n",
    "    \"BERT Count\": bert_counts\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "#add % columns\n",
    "sentiment_totals[\"VADER %\"] = (sentiment_totals[\"VADER Count\"] / total_vader * 100).round(1)\n",
    "sentiment_totals[\"BERT %\"] = (sentiment_totals[\"BERT Count\"] / total_bert * 100).round(1)\n",
    "\n",
    "#reset index so Sentiment is a column\n",
    "sentiment_totals = sentiment_totals.reset_index().rename(columns={\"index\": \"Sentiment\"})\n",
    "\n",
    "#display!\n",
    "display(sentiment_totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0da98fe-4faa-45ee-b2d6-43f6f185e477",
   "metadata": {},
   "source": [
    "## Conversely, comments left for why people have not left their current roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2175b8d2-739e-4108-9e87-3572bf5a868c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Company</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dec 13, 2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not enough time to practice Leetcode and syste...</td>\n",
       "      <td>341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dec 13, 2021</td>\n",
       "      <td>Google</td>\n",
       "      <td>Not enough time to practice all these things b...</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dec 13, 2021</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>I got a big pay bump from going from NCG salar...</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dec 14, 2021</td>\n",
       "      <td>Better.com</td>\n",
       "      <td>My incredible CEO and work culture 😃 😉 😜 😱 😢</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dec 13, 2021</td>\n",
       "      <td>EMC</td>\n",
       "      <td>I like the product I'm working on, decent wlb,...</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date     Company  \\\n",
       "0  Dec 13, 2021         NaN   \n",
       "1  Dec 13, 2021      Google   \n",
       "2  Dec 13, 2021      Amazon   \n",
       "3  Dec 14, 2021  Better.com   \n",
       "4  Dec 13, 2021         EMC   \n",
       "\n",
       "                                             Comment  Likes  \n",
       "0  Not enough time to practice Leetcode and syste...  341.0  \n",
       "1  Not enough time to practice all these things b...   90.0  \n",
       "2  I got a big pay bump from going from NCG salar...   51.0  \n",
       "3       My incredible CEO and work culture 😃 😉 😜 😱 😢  119.0  \n",
       "4  I like the product I'm working on, decent wlb,...   87.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blind comments from post 4 -- Specifically asking why have people NOT quit their current jobs\n",
    "# https://www.teamblind.com/post/Why-havent-you-quit-tLFL18Ch\n",
    "df_positive_comments = pd.read_csv(\"Blind_Post_4_Positive_Comments.csv\")\n",
    "# Dropping URL column automatically created\n",
    "df_positive_comments.drop(columns=['web-scraper-order', 'web-scraper-start-url'], inplace = True)\n",
    "df_positive_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8f313d-0ee0-4873-9c41-955469d2ac7c",
   "metadata": {},
   "source": [
    "Clearly there will be sarcasm in these comments, that will hopefully be identified with BERT analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cec8170f-a504-4a73-9785-3244df5a6749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "df_positive_comments['Likes'] = df_positive_comments['Likes'].fillna(0)  # replace NaN likes with 0\n",
    "\n",
    "#lowercase, remove punctuation/numbers\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)            #keep letters and spaces\n",
    "    return text\n",
    "\n",
    "def tokenize_no_stopword_removal(text):\n",
    "    words = text.split()\n",
    "    #keep stopwords for bigrams\n",
    "    return ' '.join([word for word in words if len(word) > 2])\n",
    "\n",
    "#apply both steps\n",
    "df_positive_comments['cleaned_text'] = df_positive_comments['Comment'].apply(clean_text)\n",
    "df_positive_comments['processed_text'] = df_positive_comments['cleaned_text'].apply(tokenize_no_stopword_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "978d8fc5-20f0-44e4-8b8c-90e0d3e83b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 30 TF-IDF Terms:\n",
      "\n",
      "                 term  average_tfidf\n",
      "          visa issues       0.019608\n",
      "           green card       0.011575\n",
      "        time leetcode       0.010803\n",
      "   stock appreciation       0.008373\n",
      "         jumping ship       0.007756\n",
      "        time practice       0.006652\n",
      "avoiding homelessness       0.006536\n",
      "    waiting liquidity       0.006536\n",
      "        stock vesting       0.006536\n",
      "      prepared taking       0.006536\n",
      "          jumped june       0.006536\n",
      "   stockholm syndrome       0.006536\n",
      "            like team       0.006536\n",
      "    immigration stuff       0.006536\n",
      "    offering nowadays       0.006536\n",
      "   immigration issues       0.006536\n",
      "        good question       0.006536\n",
      "          waiting ipo       0.006536\n",
      "             got jump       0.006536\n",
      "    waiting greencard       0.006536\n",
      "      company talking       0.006536\n",
      "    visa restrictions       0.006536\n",
      "           time study       0.006536\n",
      "       portfolio isnt       0.006536\n",
      "  potential promotion       0.006536\n",
      "             just got       0.006521\n",
      "         time prepare       0.006317\n",
      "               tc new       0.006087\n",
      "            jump ship       0.005402\n",
      "              im lazy       0.005260\n"
     ]
    }
   ],
   "source": [
    "#set up TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=\"english\",     #remove common boring words\n",
    "    ngram_range=(2,2),       #include bigrams\n",
    ")\n",
    "\n",
    "#fit TF-IDF to cleaned Blind comments\n",
    "tfidf_matrix = vectorizer.fit_transform(df_positive_comments['cleaned_text'])\n",
    "\n",
    "#convert to df\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "#get top 30 average TF-IDF terms\n",
    "top_scores = tfidf_df.mean().sort_values(ascending=False).head(30).reset_index()\n",
    "top_scores.columns = ['term', 'average_tfidf']\n",
    "\n",
    "print(\"\\nTop 30 TF-IDF Terms:\\n\")\n",
    "print(top_scores.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e5b702a3-7de6-44c0-b84e-7a28223b1218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Topic 1: 0.692*\"work\" + 0.070*\"want\" + 0.050*\"pay\" + 0.047*\"company\" + 0.038*\"stay\" + 0.032*\"year\" + 0.024*\"time\" + 0.015*\"wait\" + 0.007*\"jump\" + 0.006*\"get\"\n",
      "\n",
      " Topic 2: 0.240*\"time\" + 0.225*\"interview\" + 0.180*\"stock\" + 0.163*\"leetcode\" + 0.100*\"want\" + 0.044*\"pay\" + 0.022*\"job\" + 0.005*\"work\" + 0.005*\"company\" + 0.004*\"stay\"\n",
      "\n",
      " Topic 3: 0.389*\"jump\" + 0.362*\"wait\" + 0.172*\"pay\" + 0.029*\"time\" + 0.007*\"get\" + 0.006*\"job\" + 0.005*\"leetcode\" + 0.004*\"interview\" + 0.004*\"year\" + 0.004*\"company\"\n",
      "\n",
      " Topic 4: 0.328*\"stay\" + 0.138*\"year\" + 0.108*\"jump\" + 0.108*\"company\" + 0.079*\"job\" + 0.074*\"leetcode\" + 0.071*\"work\" + 0.046*\"interview\" + 0.018*\"time\" + 0.006*\"get\"\n",
      "\n",
      " Topic 5: 0.438*\"year\" + 0.199*\"company\" + 0.125*\"stock\" + 0.104*\"job\" + 0.066*\"pay\" + 0.030*\"time\" + 0.009*\"work\" + 0.006*\"jump\" + 0.005*\"get\" + 0.004*\"want\"\n",
      "\n",
      " Topic 6: 0.495*\"get\" + 0.120*\"time\" + 0.113*\"want\" + 0.110*\"job\" + 0.086*\"year\" + 0.023*\"stay\" + 0.008*\"stock\" + 0.008*\"pay\" + 0.006*\"jump\" + 0.006*\"leetcode\"\n"
     ]
    }
   ],
   "source": [
    "def clean_for_lda(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc \n",
    "            if token.pos_ in [\"NOUN\", \"ADJ\", \"VERB\"]\n",
    "            and not token.is_stop\n",
    "            and len(token) > 2]\n",
    "\n",
    "#apply to cleaned txt\n",
    "df_positive_comments[\"lda_tokens\"] = df_positive_comments[\"cleaned_text\"].apply(clean_for_lda)\n",
    "df_positive_comments[\"lda_tokens\"].head()\n",
    "\n",
    "#create dict that assigns an ID to every unique word (used by LDA)\n",
    "dictionary = corpora.Dictionary(df_positive_comments[\"lda_tokens\"])\n",
    "\n",
    "#filter out rare words (appear in <10 docs) and too common words (>50% of docs)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.50)\n",
    "\n",
    "#converts each doc into bag-of-words format (list of (word_id, count) pairs)\n",
    "#input format LDA needs\n",
    "corpus = [dictionary.doc2bow(text) for text in df_positive_comments[\"lda_tokens\"]]\n",
    "\n",
    "#train LDA model\n",
    "lda_model = gensim.models.LdaModel(\n",
    "    corpus=corpus,             #bag-of-words data\n",
    "    id2word=dictionary,        #word-to-ID mapping\n",
    "    num_topics=6,              #how many topics to find\n",
    "    random_state=15,           #for reproducibility \n",
    "    passes=10,                 #number of training passes (more = better, slower)\n",
    "    alpha='auto'               #automatically tune topic distribution sparsity\n",
    ")\n",
    "\n",
    "#view discovered topics \n",
    "for i, topic in lda_model.show_topics(num_words=10, formatted=True):\n",
    "    print(f\"\\n Topic {i+1}: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "98c1dac6-3d32-44bb-918e-352cbca4a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyLDAvis.enable_notebook()\n",
    "\n",
    "# vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
    "# pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7221a14b-19d4-452f-becd-53f7e8f20b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm not worried about missing out.  If I switc...</td>\n",
       "      <td>0.995</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your poll needs more answer options!\\n\\nI woul...</td>\n",
       "      <td>0.932</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't want to relocate outside of LA and dea...</td>\n",
       "      <td>0.890</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Im going to just stick with Dev Ops. It pays a...</td>\n",
       "      <td>0.882</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Culture. After a certain point (TC or Age), yo...</td>\n",
       "      <td>0.881</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Easy boss, not much pressure or work, promise ...</td>\n",
       "      <td>0.840</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Not everything in life is about money… Many of...</td>\n",
       "      <td>0.815</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>My WLB and the work I do I like. A big plus is...</td>\n",
       "      <td>0.796</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In a good position to learn and grow in this t...</td>\n",
       "      <td>0.788</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stock appreciation is terrific</td>\n",
       "      <td>0.751</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I’m Tech Recruiter @ Amazon. I hire SDE II &amp; I...</td>\n",
       "      <td>0.727</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How much of the increase is attributed to incr...</td>\n",
       "      <td>0.700</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Thanks for responding to this poll. Inspired b...</td>\n",
       "      <td>0.663</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>My manager keeps telling me you are the best w...</td>\n",
       "      <td>0.637</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I already did reached peak TC stay happy</td>\n",
       "      <td>0.625</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I like what I do well enough but the biggest i...</td>\n",
       "      <td>0.625</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I stayed at my old company for many years and ...</td>\n",
       "      <td>0.613</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Not willing to lose my 6wks annual vacation pl...</td>\n",
       "      <td>0.612</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I got a 110% bump after jumping ship. So glad ...</td>\n",
       "      <td>0.595</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Looking at the poll results, I think it's enco...</td>\n",
       "      <td>0.586</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment  sentiment_score  \\\n",
       "0   I'm not worried about missing out.  If I switc...            0.995   \n",
       "1   Your poll needs more answer options!\\n\\nI woul...            0.932   \n",
       "2   I don't want to relocate outside of LA and dea...            0.890   \n",
       "3   Im going to just stick with Dev Ops. It pays a...            0.882   \n",
       "4   Culture. After a certain point (TC or Age), yo...            0.881   \n",
       "5   Easy boss, not much pressure or work, promise ...            0.840   \n",
       "6   Not everything in life is about money… Many of...            0.815   \n",
       "7   My WLB and the work I do I like. A big plus is...            0.796   \n",
       "8   In a good position to learn and grow in this t...            0.788   \n",
       "9                      Stock appreciation is terrific            0.751   \n",
       "10  I’m Tech Recruiter @ Amazon. I hire SDE II & I...            0.727   \n",
       "11  How much of the increase is attributed to incr...            0.700   \n",
       "12  Thanks for responding to this poll. Inspired b...            0.663   \n",
       "13  My manager keeps telling me you are the best w...            0.637   \n",
       "14           I already did reached peak TC stay happy            0.625   \n",
       "15  I like what I do well enough but the biggest i...            0.625   \n",
       "16  I stayed at my old company for many years and ...            0.613   \n",
       "17  Not willing to lose my 6wks annual vacation pl...            0.612   \n",
       "18  I got a 110% bump after jumping ship. So glad ...            0.595   \n",
       "19  Looking at the poll results, I think it's enco...            0.586   \n",
       "\n",
       "   vader_sentiment  \n",
       "0         Positive  \n",
       "1         Positive  \n",
       "2         Positive  \n",
       "3         Positive  \n",
       "4         Positive  \n",
       "5         Positive  \n",
       "6         Positive  \n",
       "7         Positive  \n",
       "8         Positive  \n",
       "9         Positive  \n",
       "10        Positive  \n",
       "11        Positive  \n",
       "12        Positive  \n",
       "13        Positive  \n",
       "14        Positive  \n",
       "15        Positive  \n",
       "16        Positive  \n",
       "17        Positive  \n",
       "18        Positive  \n",
       "19        Positive  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#apply VADER sentiment to each cleaned comment \n",
    "df_positive_comments[\"sentiment_score\"] = df_positive_comments[\"cleaned_text\"].apply(lambda text: vader.polarity_scores(text)[\"compound\"])\n",
    "\n",
    "#preview df\n",
    "sentiment_preview = df_positive_comments[[\"Comment\", \"sentiment_score\"]].copy()\n",
    "\n",
    "#round for neatness\n",
    "sentiment_preview[\"sentiment_score\"] = sentiment_preview[\"sentiment_score\"].round(3)\n",
    "\n",
    "#sort by most negative sentiment\n",
    "sentiment_preview = sentiment_preview.sort_values(by=\"sentiment_score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "def label_sentiment(score):\n",
    "    if score >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "df_positive_comments[\"vader_sentiment\"] = df_positive_comments[\"sentiment_score\"].apply(label_sentiment)\n",
    "\n",
    "#display table w/sentiment score & whether it's pos, neut, or neg.\n",
    "sentiment_table = df_positive_comments[[\"Comment\", \"sentiment_score\", \"vader_sentiment\"]].copy()\n",
    "sentiment_table[\"sentiment_score\"] = sentiment_table[\"sentiment_score\"].round(3)\n",
    "sentiment_table = sentiment_table.sort_values(by=\"sentiment_score\", ascending=False).reset_index(drop=True)\n",
    "display(sentiment_table.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "631e292a-1fb8-4a7a-996a-2b599e1d4d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>46</td>\n",
       "      <td>30.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>51</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>56</td>\n",
       "      <td>36.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment  Count  Percent\n",
       "2  Negative     46     30.1\n",
       "1   Neutral     51     33.3\n",
       "0  Positive     56     36.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#count the # of comments in each sentiment category\n",
    "sentiment_counts = df_positive_comments[\"vader_sentiment\"].value_counts().reset_index()\n",
    "sentiment_counts.columns = [\"Sentiment\", \"Count\"]\n",
    "\n",
    "#calculate percentage\n",
    "total_comments = sentiment_counts[\"Count\"].sum()\n",
    "sentiment_counts[\"Percent\"] = (sentiment_counts[\"Count\"] / total_comments * 100).round(1)\n",
    "\n",
    "#display\n",
    "sentiment_counts = sentiment_counts.sort_values(by=\"Sentiment\")  # Optional alphabetical sort\n",
    "display(sentiment_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08767b16-ab93-412b-accf-f8d476d06d97",
   "metadata": {},
   "source": [
    "## Bert application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "55f3fcac-a075-4cdb-96da-9f2545ae5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run BERT Sentiment on comments\n",
    "#load the model & tokenizer\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "#function to get sentiment label\n",
    "def get_bert_sentiment(text):\n",
    "    #512 tokens max or it breaks\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    probs = softmax(logits.numpy()[0])\n",
    "    \n",
    "    label_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "    return label_map[probs.argmax()]\n",
    "\n",
    "\n",
    "#apply to df\n",
    "df_positive_comments[\"bert_sentiment\"] = df_positive_comments[\"Comment\"].apply(get_bert_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7919de02-4cc7-4b3a-8132-ff08ff3116c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>bert_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not enough time to practice Leetcode and syste...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not enough time to practice all these things b...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I got a big pay bump from going from NCG salar...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My incredible CEO and work culture 😃 😉 😜 😱 😢</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like the product I'm working on, decent wlb,...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Looking at the poll results, I think it's enco...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fear of the unknown and/or laziness is almost ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>takes me too long to brush up LC</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Imposter syndrome.  Feels like I’m already und...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>working 80 hour weeks and too tired to LC afte...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment bert_sentiment\n",
       "0  Not enough time to practice Leetcode and syste...       Negative\n",
       "1  Not enough time to practice all these things b...       Negative\n",
       "2  I got a big pay bump from going from NCG salar...       Positive\n",
       "3       My incredible CEO and work culture 😃 😉 😜 😱 😢       Positive\n",
       "4  I like the product I'm working on, decent wlb,...       Positive\n",
       "5  Looking at the poll results, I think it's enco...       Positive\n",
       "6  Fear of the unknown and/or laziness is almost ...        Neutral\n",
       "7                   takes me too long to brush up LC       Negative\n",
       "8  Imposter syndrome.  Feels like I’m already und...       Negative\n",
       "9  working 80 hour weeks and too tired to LC afte...       Negative"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_positive_comments[[\"Comment\", \"bert_sentiment\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "baa8ba1b-7313-4b6e-b544-5d096436354b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>70</td>\n",
       "      <td>45.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>52</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>31</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment  Count  Percent\n",
       "0   Neutral     70     45.8\n",
       "1  Negative     52     34.0\n",
       "2  Positive     31     20.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_counts = df_positive_comments[\"bert_sentiment\"].value_counts().reset_index()\n",
    "bert_counts.columns = [\"Sentiment\", \"Count\"]\n",
    "bert_counts[\"Percent\"] = (bert_counts[\"Count\"] / bert_counts[\"Count\"].sum() * 100).round(1)\n",
    "\n",
    "display(bert_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0f3b4bac-c4e7-4025-a5d1-2c3aaf5d3138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>VADER Count</th>\n",
       "      <th>BERT Count</th>\n",
       "      <th>VADER %</th>\n",
       "      <th>BERT %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>30.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>51</td>\n",
       "      <td>70</td>\n",
       "      <td>33.3</td>\n",
       "      <td>45.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>56</td>\n",
       "      <td>31</td>\n",
       "      <td>36.6</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment  VADER Count  BERT Count  VADER %  BERT %\n",
       "0  Negative           46          52     30.1    34.0\n",
       "1   Neutral           51          70     33.3    45.8\n",
       "2  Positive           56          31     36.6    20.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get counts\n",
    "vader_counts = df_positive_comments[\"vader_sentiment\"].value_counts().sort_index()\n",
    "bert_counts = df_positive_comments[\"bert_sentiment\"].value_counts().sort_index()\n",
    "\n",
    "#get total for each model\n",
    "total_vader = vader_counts.sum()\n",
    "total_bert = bert_counts.sum()\n",
    "\n",
    "#combine into one df\n",
    "sentiment_totals = pd.DataFrame({\n",
    "    \"VADER Count\": vader_counts,\n",
    "    \"BERT Count\": bert_counts\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "#add % columns\n",
    "sentiment_totals[\"VADER %\"] = (sentiment_totals[\"VADER Count\"] / total_vader * 100).round(1)\n",
    "sentiment_totals[\"BERT %\"] = (sentiment_totals[\"BERT Count\"] / total_bert * 100).round(1)\n",
    "\n",
    "#reset index so Sentiment is a column\n",
    "sentiment_totals = sentiment_totals.reset_index().rename(columns={\"index\": \"Sentiment\"})\n",
    "\n",
    "#display!\n",
    "display(sentiment_totals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
